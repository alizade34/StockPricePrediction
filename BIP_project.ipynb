{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Trading Strategy\n",
    "\n",
    "## Objective\n",
    "The objective of this project is to develop an AI-driven intraday trading strategy using reinforcement learning and deep learning techniques. The focus is on leveraging the IVV ETF data to create models that predict short-term market movements and optimize trading decisions.\n",
    "\n",
    "## Team Composition\n",
    "- Emil Alizada\n",
    "- Ritwick Haldar\n",
    "- Muhammad Zubair Ahmed Khan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setting Environment Variables\n",
    "Set environment variables to control TensorFlow and matplotlib behaviors, ensuring that TensorFlow runs on the CPU and that matplotlib runs in an offscreen mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress all logs except errors\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # Force TensorFlow to use CPU\n",
    "os.environ['QT_QPA_PLATFORM'] = 'offscreen'  # Suppress Qt backend issues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Data\n",
    "Load the training and validation datasets for the IVV ETF. We use a subset of the data for testing purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data = pd.read_csv('IVV_1m_training.csv') # Using a subset for testing\n",
    "val_data = pd.read_csv('IVV_1m_validation.csv')  # Using a subset for testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Preprocessing\n",
    "Preprocess the data by adding technical indicators such as Simple Moving Average (SMA), Relative Strength Index (RSI), Moving Average Convergence Divergence (MACD), and Bollinger Bands.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    data['DateTime'] = pd.to_datetime(data['DateTime'])\n",
    "    data.set_index('DateTime', inplace=True)\n",
    "    data['SMA'] = data['Close'].rolling(window=20).mean()\n",
    "    data['RSI'] = compute_RSI(data['Close'], 14)\n",
    "    data['MACD'] = compute_MACD(data['Close'])\n",
    "    data['BB_upper'], data['BB_middle'], data['BB_lower'] = compute_Bollinger_Bands(data['Close'])\n",
    "    data.dropna(inplace=True)\n",
    "    return data\n",
    "\n",
    "def compute_RSI(data, window):\n",
    "    diff = data.diff(1)\n",
    "    gain = diff.clip(lower=0)\n",
    "    loss = -1 * diff.clip(upper=0)\n",
    "    avg_gain = gain.rolling(window=window).mean()\n",
    "    avg_loss = loss.rolling(window=window).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def compute_MACD(data, slow=26, fast=12, signal=9):\n",
    "    ema_fast = data.ewm(span=fast, min_periods=fast).mean()\n",
    "    ema_slow = data.ewm(span=slow, min_periods=slow).mean()\n",
    "    macd = ema_fast - ema_slow\n",
    "    signal_line = macd.ewm(span=signal, min_periods=signal).mean()\n",
    "    return macd - signal_line\n",
    "\n",
    "def compute_Bollinger_Bands(data, window=20, num_std=2):\n",
    "    rolling_mean = data.rolling(window=window).mean()\n",
    "    rolling_std = data.rolling(window=window).std()\n",
    "    upper_band = rolling_mean + (rolling_std * num_std)\n",
    "    lower_band = rolling_mean - (rolling_std * num_std)\n",
    "    return upper_band, rolling_mean, lower_band\n",
    "\n",
    "train_data = preprocess_data(train_data)\n",
    "val_data = preprocess_data(val_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Data Normalization\n",
    "Normalize the data using `StandardScaler` to ensure that all features have a mean of 0 and a standard deviation of 1, which is essential for training the LSTM model effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "scaler = StandardScaler()\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "val_data_scaled = scaler.transform(val_data)\n",
    "joblib.dump(scaler, \"scaler.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Breakout Strategy\n",
    "Implement a breakout strategy to label the data with buy and sell signals. This strategy identifies potential breakout points based on the highest and lowest prices over a specified look-back period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breakout_strategy(data, lookback=20):\n",
    "    data['High_max'] = data['High'].rolling(window=lookback).max()\n",
    "    data['Low_min'] = data['Low'].rolling(window=lookback).min()\n",
    "    data['Buy'] = np.where(data['Close'] > data['High_max'].shift(1), 1, 0)\n",
    "    data['Sell'] = np.where(data['Close'] < data['Low_min'].shift(1), 1, 0)\n",
    "    return data\n",
    "\n",
    "train_data = breakout_strategy(train_data)\n",
    "val_data = breakout_strategy(val_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Prepare Data for LSTM\n",
    "Create a dataset for the LSTM model with the specified look-back period. This step involves reshaping the data into sequences that the LSTM model can process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(data) - look_back - 1):\n",
    "        a = data[i:(i + look_back), :-1]\n",
    "        X.append(a)\n",
    "        Y.append(data[i + look_back, -1])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "look_back = 60  # 60 minutes look back\n",
    "X_train, y_train = create_dataset(train_data_scaled, look_back)\n",
    "X_val, y_val = create_dataset(val_data_scaled, look_back)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Build and Train LSTM Model\n",
    "Build the LSTM model using Keras, compile it with the Adam optimizer and mean squared error loss function, and then train the model on the prepared training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(look_back, X_train.shape[2])))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=50, validation_data=(X_val, y_val))\n",
    "\n",
    "# Save the model using Keras' save method\n",
    "model.save('lstm_model.h5')\n",
    "print(\"LSTM model savedÂ successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Define Trading Environment\n",
    "Create a custom trading environment using the OpenAI Gym framework. This environment simulates trading activities and evaluates the performance of the reinforcement learning agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingEnv(gym.Env):\n",
    "    def __init__(self, data, initial_balance=10000, stop_loss=0.005, take_profit=0.01, min_trades=2, max_trades=8, trading_cost=0.0001):\n",
    "        super(TradingEnv, self).__init__()\n",
    "        self.data = data\n",
    "        self.current_step = 0\n",
    "        self.initial_balance = initial_balance\n",
    "        self.balance = initial_balance\n",
    "        self.stop_loss = stop_loss\n",
    "        self.take_profit = take_profit\n",
    "        self.position = 0  # 0: no position, 1: long, -1: short\n",
    "        self.entry_price_long = 0\n",
    "        self.entry_price_short = 0\n",
    "        self.trades_per_day = 0\n",
    "        self.min_trades = min_trades\n",
    "        self.max_trades = max_trades\n",
    "        self.current_day = self.current_step\n",
    "        self.daily_trades = []\n",
    "        self.daily_profits = []\n",
    "        self.trading_cost = trading_cost  # Trading cost percentage\n",
    "\n",
    "        self.action_space = spaces.Discrete(3)  # buy, sell, hold\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(look_back, data.shape[1]), dtype=np.float32)\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.balance = self.initial_balance\n",
    "        self.position = 0\n",
    "        self.entry_price_long = 0\n",
    "        self.entry_price_short = 0\n",
    "        self.trades_per_day = 0\n",
    "        self.daily_trades = []\n",
    "        self.daily_profits = []\n",
    "        return self.data[self.current_step:self.current_step + look_back]\n",
    "\n",
    "    def step(self, action):\n",
    "        reward = 0\n",
    "        done = self.current_step >= len(self.data) - look_back - 1\n",
    "\n",
    "        # Take action\n",
    "        current_price = self.data[self.current_step][-1]\n",
    "        if action == 1:  # buy\n",
    "            if self.position == 0 and self.trades_per_day < self.max_trades:\n",
    "                self.position = 1\n",
    "                self.entry_price_long = current_price\n",
    "                self.trades_per_day += 1\n",
    "            elif self.position == -1:  # if already short, open long too\n",
    "                self.position = 2  # indicating both long and short positions\n",
    "                self.entry_price_long = current_price\n",
    "        elif action == 2:  # sell\n",
    "            if self.position == 0 and self.trades_per_day < self.max_trades:\n",
    "                self.position = -1\n",
    "                self.entry_price_short = current_price\n",
    "                self.trades_per_day += 1\n",
    "            elif self.position == 1:  # if already long, open short too\n",
    "                self.position = 2  # indicating both long and short positions\n",
    "                self.entry_price_short = current_price\n",
    "        elif action == 0:  # hold\n",
    "            pass\n",
    "\n",
    "        # Check stop-loss and take-profit conditions\n",
    "        if self.position == 1:\n",
    "            if (current_price <= self.entry_price_long * (1 - self.stop_loss)) or (current_price >= self.entry_price_long * (1 + self.take_profit)):\n",
    "                trade_value = min(self.balance, self.balance * (1 - self.trading_cost))  # Adjusting for trading cost\n",
    "                reward = (current_price - self.entry_price_long) * (trade_value / self.entry_price_long)\n",
    "                self.balance += reward\n",
    "                self.position = 0\n",
    "        elif self.position == -1:\n",
    "            if (current_price >= self.entry_price_short * (1 + self.stop_loss)) or (current_price <= self.entry_price_short * (1 - self.take_profit)):\n",
    "                trade_value = min(self.balance, self.balance * (1 - self.trading_cost))  # Adjusting for trading cost\n",
    "                reward = (self.entry_price_short - current_price) * (trade_value / self.entry_price_short)\n",
    "                self.balance += reward\n",
    "                self.position = 0\n",
    "        elif self.position == 2:\n",
    "            # Check long position\n",
    "            if (current_price <= self.entry_price_long * (1 - self.stop_loss)) or (current_price >= self.entry_price_long * (1 + self.take_profit)):\n",
    "                trade_value_long = min(self.balance, self.balance * (1 - self.trading_cost))  # Adjusting for trading cost\n",
    "                reward_long = (current_price - self.entry_price_long) * (trade_value_long / self.entry_price_long)\n",
    "                if reward_long < 0:  # if long is in loss, close it\n",
    "                    self.position = -1\n",
    "                else:  # if long is in profit, open another long\n",
    "                    self.balance += reward_long\n",
    "                    reward += reward_long\n",
    "                    self.position = 1  # keep the short position open\n",
    "            # Check short position\n",
    "            if (current_price >= self.entry_price_short * (1 + self.stop_loss)) or (current_price <= self.entry_price_short * (1 - self.take_profit)):\n",
    "                trade_value_short = min(self.balance, self.balance * (1 - self.trading_cost))  # Adjusting for trading cost\n",
    "                reward_short = (self.entry_price_short - current_price) * (trade_value_short / self.entry_price_short)\n",
    "                if reward_short < 0:  # if short is in loss, close it\n",
    "                    self.position = 1\n",
    "                else:  # if short is in profit, open another short\n",
    "                    self.balance += reward_short\n",
    "                    reward += reward_short\n",
    "                    self.position = -1  # keep the long position open\n",
    "\n",
    "        self.current_step += 1\n",
    "\n",
    "                        # Check if it's a new day\n",
    "        if self.current_step % 1440 == 0:  # Assuming one day is 1440 minutes\n",
    "            if self.trades_per_day < self.min_trades:\n",
    "                reward -= 100  # Penalty for not meeting the minimum trades requirement\n",
    "            if self.position != 0:\n",
    "                # Close position at market price at the end of the day\n",
    "                if self.position == 1:\n",
    "                    trade_value = min(self.balance, self.balance * (1 - self.trading_cost))  # Adjusting for trading cost\n",
    "                    reward += (current_price - self.entry_price_long) * (trade_value / self.entry_price_long)\n",
    "                elif self.position == -1:\n",
    "                    trade_value = min(self.balance, self.balance * (1 - self.trading_cost))  # Adjusting for trading cost\n",
    "                    reward += (self.entry_price_short - current_price) * (trade_value / self.entry_price_short)\n",
    "                reward -= abs(reward * self.trading_cost)  # Deduct trading cost\n",
    "                self.balance += reward\n",
    "                self.position = 0\n",
    "            self.daily_trades.append(self.trades_per_day)\n",
    "            self.daily_profits.append(self.balance - self.initial_balance)\n",
    "            self.trades_per_day = 0\n",
    "\n",
    "        state = self.data[self.current_step:self.current_step + look_back]\n",
    "        return state, reward, done, {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Load Trained Model and Test Environment\n",
    "Load the trained model and evaluate it in the custom trading environment. This involves running the reinforcement learning agent and recording the actions, rewards, and overall performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the trading environment\n",
    "train_env = TradingEnv(train_data_scaled)\n",
    "val_env = TradingEnv(val_data_scaled)\n",
    "\n",
    "# Train the PPO model\n",
    "drl_model = PPO('MlpPolicy', train_env, verbose=1)\n",
    "drl_model.learn(total_timesteps=10000)  # Adjust timesteps as needed\n",
    "\n",
    "# Save the trained model\n",
    "drl_model.save(\"drl_trading_model\")\n",
    "print(\"Model trained and savedÂ successfully.\")\n",
    "# Load the trained model\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "drl_model = PPO.load(\"drl_trading_model\")\n",
    "val_env = TradingEnv(val_data_scaled)\n",
    "\n",
    "state = val_env.reset()\n",
    "done = False\n",
    "\n",
    "cumulative_return = []\n",
    "actions = []\n",
    "profits = []\n",
    "initial_balance = 10000  # Starting with $10,000\n",
    "successful_trades = 0\n",
    "total_trades = 0\n",
    "\n",
    "current_balance = initial_balance\n",
    "\n",
    "# Define variables to track net profit\n",
    "net_profit = 0\n",
    "total_trade_amount = 0\n",
    "\n",
    "while not done:\n",
    "    action, _states = drl_model.predict(state)\n",
    "    state, reward, done, info = val_env.step(action)\n",
    "    current_balance += reward\n",
    "    profits.append(reward)\n",
    "    cumulative_return.append(current_balance)\n",
    "    actions.append(action)\n",
    "\n",
    "    # Update successful trades count\n",
    "    if reward > 0:\n",
    "        successful_trades += 1\n",
    "    total_trades += 1\n",
    "\n",
    "    # Update net profit and total trade amount\n",
    "    if reward != 0:\n",
    "        net_profit += reward\n",
    "        total_trade_amount += np.abs(reward)\n",
    "\n",
    "    # Print trade details\n",
    "    if reward != 0:\n",
    "        current_date_time = val_data.index[val_env.current_step]\n",
    "        print(f\"Trade Details:\")\n",
    "        print(f\"Date and Time: {current_date_time}\")\n",
    "        print(f\"Action: {'Buy' if action == 1 else 'Sell'}\")\n",
    "        print(f\"Reward: {reward}\")\n",
    "\n",
    "# Calculate cumulative return in percentage\n",
    "cumulative_return = np.array(cumulative_return)\n",
    "cumulative_return = (cumulative_return - initial_balance) / initial_balance * 100  # Percentage return\n",
    "\n",
    "# Calculate success accuracy\n",
    "success_accuracy = (successful_trades / total_trades) * 100\n",
    "\n",
    "# Store results in a DataFrame\n",
    "results = pd.DataFrame({\n",
    "    'cumulative_return': cumulative_return,\n",
    "    'actions': actions,\n",
    "    'profits': profits\n",
    "})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting buy and sell signals on training data\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(train_data.index, train_data['Close'], label='Close')\n",
    "plt.scatter(train_data.index[train_data['Buy'] == 1], train_data['Close'][train_data['Buy'] == 1], marker='^', color='g', label='Buy', alpha=1)\n",
    "plt.scatter(train_data.index[train_data['Sell'] == 1], train_data['Close'][train_data['Sell'] == 1], marker='v', color='r', label='Sell', alpha=1)\n",
    "plt.title('Training data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()  # Show the plot\n",
    "\n",
    "# Plotting buy and sell signals on validation data\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(val_data.index, val_data['Close'], label='Close')\n",
    "plt.scatter(val_data.index[val_data['Buy'] == 1], val_data['Close'][val_data['Buy'] == 1], marker='^', color='g', label='Buy', alpha=1)\n",
    "plt.scatter(val_data.index[val_data['Sell'] == 1], val_data['Close'][val_data['Sell'] == 1], marker='v', color='r', label='Sell', alpha=1)\n",
    "plt.title('Validation data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()  # Show the plot\n",
    "\n",
    "# Plot actions taken by the agent\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(results.index, results['actions'], label='Actions')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Action')\n",
    "plt.title('Actions Taken by the Trading Agent')\n",
    "plt.legend()\n",
    "plt.show()  # Show the plot\n",
    "\n",
    "# Plot profits per trade\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(results.index, results['profits'], label='Profit per Trade')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Profit')\n",
    "plt.title('Profit per Trade Over Time')\n",
    "plt.legend()\n",
    "plt.show()  # Show the plot\n",
    "\n",
    "print(\"Plots displayed successfully.\")\n",
    "\n",
    "print(f\"Success Accuracy: {success_accuracy:.2f}%\")\n",
    "\n",
    "# Example of detailed output\n",
    "net_worth = initial_balance + net_profit\n",
    "balance = val_env.balance\n",
    "trades_per_day = np.mean(val_env.daily_trades)\n",
    "\n",
    "print(f\"Net Profit: {net_profit}\")\n",
    "print(f\"Net Worth: {net_worth}\")\n",
    "print(f\"Balance: {balance}\")\n",
    "print(f\"Trades: {total_trades}\")\n",
    "print(f\"Trades per day: {trades_per_day}\")\n",
    "\n",
    "np.seterr(divide='warn',invalid='warn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Calculate Metrics\n",
    "Calculate important trading performance metrics such as cumulative returns, compounded annual return, annual volatility, Value at Risk (VaR), Conditional Value at Risk (CVaR), Sharpe Ratio, and Sortino Ratio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "# Calculate cumulative returns (%)\n",
    "final_balance = net_worth  # Assuming net_worth represents the final balance\n",
    "cumulative_returns = ((final_balance - initial_balance) / initial_balance) * 1\n",
    "\n",
    "# Compounded annual return (%)\n",
    "start_date = pd.to_datetime(results.index[0])\n",
    "end_date = pd.to_datetime(results.index[-1])\n",
    "num_days = (end_date - start_date).days\n",
    "num_years = num_days / 365.25 if num_days > 365.25 else 1  # Prevent division by zero\n",
    "compounded_annual_return = ((net_worth / initial_balance) ** (1 / num_years) - 1) * 100\n",
    "\n",
    "# Annual volatility\n",
    "annual_volatility = np.std(results['cumulative_return'].pct_change().dropna()) * np.sqrt(252) * 100  # Assuming 252 trading days in a year\n",
    "\n",
    "# VaR Hist (Value at Risk)\n",
    "var_hist = np.percentile(results['cumulative_return'], 5)  # 5% VaR\n",
    "\n",
    "# CVaR Hist (Conditional Value at Risk)\n",
    "cvar_hist = results['cumulative_return'][results['cumulative_return'] <= var_hist].mean()\n",
    "\n",
    "# Sharpe Ratio\n",
    "daily_returns = results['cumulative_return'].pct_change().dropna()\n",
    "sharpe_ratio = (daily_returns.mean() / daily_returns.std()) * np.sqrt(252)  # Assuming 252 trading days in a year\n",
    "\n",
    "# Sortino Ratio\n",
    "downside_returns = daily_returns[daily_returns < 0]\n",
    "sortino_ratio = (daily_returns.mean() / downside_returns.std()) * np.sqrt(252)\n",
    "\n",
    "# Print or use the calculated metrics as needed\n",
    "print(\"Cumulative Returns (%):\", cumulative_returns)\n",
    "print(\"Compounded Annual Return (%):\", compounded_annual_return)\n",
    "print(\"Annual Volatility:\", annual_volatility)\n",
    "print(\"VaR Hist:\", var_hist)\n",
    "print(\"CVaR Hist:\", cvar_hist)\n",
    "print(\"Sharpe Ratio:\", sharpe_ratio)\n",
    "print(\"Sortino Ratio:\", sortino_ratio)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
